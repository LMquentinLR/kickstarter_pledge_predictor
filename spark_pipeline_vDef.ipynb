{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Pipeline on Kickstarter Pledge Dataset\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "### 1.1. Instructions\n",
    "\n",
    "- **Choosing any sufficiently large open dataset** (less than 100000 lines are not allowed)\n",
    "\n",
    "\n",
    "- **Choosing one variable to predict**\n",
    "\n",
    "\n",
    "- **Implementing at least two supervised learning models**: classification, regression, recommender system, etc. Unsupervised tasks (e.g. clusterisation, associative rules, etc.) are not allowed\n",
    "\n",
    "\n",
    "- **Mandatory use of Apache Spark** (e.g. on Google Cloud as we did during our lab sessions)\n",
    "\n",
    "\n",
    "- A **full machine learning pipeline must be implemented**, which include:\n",
    "    - Reading the data\n",
    "    - Transforming data (extracting features, dealing with missing values if any, etc.)\n",
    "    - Building models (build at least two models to compare)\n",
    "    - Evaluating quality (use cross-validation or train/test split)\n",
    "\n",
    "### 1.2. Dataset\n",
    "\n",
    "We will be using the [Kickstarter Projects](https://www.kaggle.com/kemical/kickstarter-projects) Kaggle dataset. It contains two .csv files dated December 2016 and January 2018 which contains lists of kickstarter campaigns, explicited with the following data fields:\n",
    "\n",
    "- ID\n",
    "- name\n",
    "- category\n",
    "- main_category\n",
    "- currency\n",
    "- deadline\n",
    "- goal\n",
    "- launched\n",
    "- pledged\n",
    "- state\n",
    "- backers\n",
    "- country\n",
    "- usd_pledged: conversion in US dollars of the pledged column \n",
    "- usd_pledged_real: conversion in US dollars of the pledged column\n",
    "- usd_goal_real: conversion in US dollars of the goal column\n",
    "\n",
    "\n",
    "### 1.3. Goal\n",
    "\n",
    "Our goal will be to predict the **state** value of campaigns based on any number other columns (our features), excluding *usd_pledged* and *usd_pledged_real*.\n",
    "\n",
    "The notebook was also ran locally using the installation steps for Spark described [here](https://sparkbyexamples.com/spark/spark-installation-on-linux-ubuntu/).\n",
    "\n",
    "## 2. Environment Set-Up\n",
    "\n",
    "We need the following libraries installed to set up the environment:\n",
    "\n",
    "- kaggle (see documentation [here](https://github.com/Kaggle/kaggle-api#datasets))\n",
    "- pyspark (see documentation [here](https://spark.apache.org/docs/latest/api/python/index.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/qlr/anaconda3/lib/python3.8/site-packages (1.5.10)\n",
      "Requirement already satisfied: urllib3 in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10 in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: requests in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: python-slugify in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: tqdm in /home/qlr/anaconda3/lib/python3.8/site-packages (from kaggle) (4.50.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/qlr/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/qlr/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/qlr/anaconda3/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: pyspark in /home/qlr/anaconda3/lib/python3.8/site-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/qlr/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "# Installs the kaggle and pyspark module on the machine\n",
    "!pip install kaggle\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes previously existing files\n",
    "!rm -f kickstarter-projects.zip\n",
    "!rm -f ks-projects-201612.csv ks-projects-201801.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Setting up Kaggle environment variables with the kaggle.json file\n",
    "\n",
    "#### 3.1.2. On Google Cloud\n",
    "\n",
    "<span style=\"color:red\">To download the kaggle dataset, we must first upload our account's **kaggle.json file** in the **/root/.kaggle/ folder**.</span>\n",
    "    \n",
    "<span style=\"color:red\">The kaggle.json file can be downloaded here:</span>\n",
    "\n",
    "> ``https://www.kaggle.com/<username>/account``\n",
    "    \n",
    "<span style=\"color:red\">It is assumed we created a **/home/\\<user\\>/ folder** where this Jupyter Notebook and the kaggle.json file have been uploaded</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## WARNING ###########\n",
    "# RUN ONLY WHEN USING GOOGLE CLOUD\n",
    "##################################\n",
    "\n",
    "# Given this notebook and the kaggle.json file are set in the folder /home/<user>/\n",
    "# Moves the kaggle.json file from the user folder to the root folder\n",
    "!mv home/qlr/kaggle.json /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. On a local machine\n",
    "    \n",
    "<span style=\"color:red\">Download and move the kaggle.json file to the local /root/.kaggle/ folder.</span>\n",
    "\n",
    "### 3.2. Downloading the dataset\n",
    "\n",
    "We only keep 'ks-projects-201801.csv', the most recent dataset available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/qlr/.kaggle/kaggle.json'\n",
      "Downloading kickstarter-projects.zip to /home/qlr/Programming/kickstarter_pledge_prediction\n",
      "100%|██████████████████████████████████████| 36.8M/36.8M [00:05<00:00, 5.64MB/s]\n",
      "100%|██████████████████████████████████████| 36.8M/36.8M [00:05<00:00, 6.85MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Dowloads the raw dataset from the kaggle source\n",
    "!kaggle datasets download -d kemical/kickstarter-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  kickstarter-projects.zip\n",
      "  inflating: ks-projects-201612.csv  \n",
      "  inflating: ks-projects-201801.csv  \n"
     ]
    }
   ],
   "source": [
    "# Unzips the raw dataset and keeps only the most recent instance\n",
    "!unzip kickstarter-projects.zip\n",
    "!rm -f ks-projects-201612.csv kickstarter-projects.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Zips the raw dataset once instantiated in memory\n",
    "# Useful for git push as Github gives a warning when pushing a file > 50Mb\n",
    "!zip ks-projects-201801.zip ks-projects-201801.csv\n",
    "!rm -f ks-projects-201801.csv\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Uploading to HDFS when using Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## WARNING ###########\n",
    "# RUN ONLY WHEN USING GOOGLE CLOUD\n",
    "##################################\n",
    "\n",
    "# Uploads the dataset to HDFS when on Google Cloud\n",
    "!hdfs dfs -mkdir /user/qlr\n",
    "!hdfs dfs -rm /user/qlr/ks-projects-201801.csv\n",
    "!hdfs dfs -put ks-projects-201801.csv /user/qlr\n",
    "!hdfs dfs -ls /user/qlr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Library Imports & Setting Spark/Global Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the needed modules\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.feature import Word2Vec, Tokenizer, HashingTF\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import unix_timestamp, ceil, isnan, when, count, col\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## WARNING ###########\n",
    "# RUN ONLY WHEN ON A LOCAL MACHINE\n",
    "##################################\n",
    "\n",
    "dataset_path = \"ks-projects-201801.csv\"\n",
    "dataset_format = \"csv\"\n",
    "context = \"local\"\n",
    "\n",
    "# Instantiates a local Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .appName('distributed-database-assignment') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## WARNING ###########\n",
    "# RUN ONLY WHEN USING GOOGLE CLOUD\n",
    "##################################\n",
    "\n",
    "dataset_path = \"/user/qlr/ks-projects-201801.csv\"\n",
    "dataset_format = \"csv\"\n",
    "context = \"cloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading the Kickstarter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Comment out the following cell when when running the notebook Google Cloud as a spark session is automatically instantiated.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://desktop-lkaf740-2.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>distributed-database-assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6432b647c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spark UI on Google Cloud should return:\n",
    "#   v2.3.4 (version)\n",
    "#   yarn (Master)\n",
    "#   PySparkShell (AppName)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the dataset\n",
    "campaigns = (spark\n",
    "             .read\n",
    "             .format(dataset_format)\n",
    "             .options(header=True)\n",
    "             .load(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares variables for pre-processing the dataset\n",
    "kept_raw_columns = [\n",
    "    \"ID\",\"name\",\"category\",\"deadline\",\"launched\",\"country\",\"usd_goal_real\", #features\n",
    "    \"state\" # target\n",
    "]\n",
    "\n",
    "remove_date_columns = [\n",
    "    \"ID\",\"name\",\"category\",\"total_duration\",\"country\",\"usd_goal_real\", #features\n",
    "    \"state\" # target\n",
    "]\n",
    "\n",
    "kept_columns_for_modelization = [\n",
    "    \"total_duration\",\"usd_goal_real\",\"name\",\"category\",\"country\", #features\n",
    "    \"state\" # target\n",
    "]\n",
    "\n",
    "deadline_format = \"yyyy-MM-dd\"\n",
    "launched_format = \"yyyy-MM-dd HH:mm:ss\"\n",
    "\n",
    "final_columns = [\"features\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares useful functions\n",
    "def dataset_check(db):\n",
    "    print(\"The dataset contains \" + str(db.count()) + \" rows.\")\n",
    "    db.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'string'),\n",
       " ('name', 'string'),\n",
       " ('category', 'string'),\n",
       " ('main_category', 'string'),\n",
       " ('currency', 'string'),\n",
       " ('deadline', 'string'),\n",
       " ('goal', 'string'),\n",
       " ('launched', 'string'),\n",
       " ('pledged', 'string'),\n",
       " ('state', 'string'),\n",
       " ('backers', 'string'),\n",
       " ('country', 'string'),\n",
       " ('usd pledged', 'string'),\n",
       " ('usd_pledged_real', 'string'),\n",
       " ('usd_goal_real', 'string')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the type of the dataset columns\n",
    "campaigns.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drops NAs, Nulls, and Duplicates \n",
    "campaigns = campaigns.dropna()\n",
    "campaigns = campaigns.dropDuplicates()\n",
    "for column in campaigns.columns:\n",
    "    campaigns = campaigns.where(col(column).isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prunes the non-relevant columns\n",
    "campaigns = campaigns.select(kept_raw_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computes a duration time (in day) between the launch and deadline features\n",
    "launch_times = unix_timestamp(\"launched\", format = launched_format)\n",
    "deadline_times = unix_timestamp(\"deadline\", format = deadline_format)\n",
    "time_difference = deadline_times - launch_times\n",
    "campaigns = campaigns.withColumn(\"total_duration\",ceil(time_difference/(3600*24)))\n",
    "\n",
    "# Removes the launch and deadline feature columns\n",
    "campaigns = campaigns.select(remove_date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the target labels:\n",
    "#   - 'undefined', 'live' -> dropped\n",
    "for condition in ['state!=\"undefined\"', 'state!=\"live\"']:\n",
    "    campaigns = campaigns.where(condition)\n",
    "\n",
    "#   - 'suspended', 'cancelled' -> renamed to 'failed' \n",
    "campaigns = campaigns.\\\n",
    "    withColumn(\"state\",when(col(\"state\") == \"canceled\", \"failed\").\\\n",
    "    when(col(\"state\") == \"suspended\", \"failed\").\\\n",
    "    when(col(\"state\") == \"failed\", \"failed\").\\\n",
    "    otherwise(\"successful\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casts the relevant column(s) to their end types\n",
    "for column in [\"total_duration\", \"usd_goal_real\"]:\n",
    "    campaigns = campaigns.withColumn(column,col(column).cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finishes clean-up\n",
    "processed_campaigns = campaigns.select(kept_columns_for_modelization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the preprocessed campaigns, we can both explore the data better and build our Spark pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Exploring the pre-processed campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 372060 rows.\n",
      "+--------------+-------------+--------------------+--------------+-------+----------+\n",
      "|total_duration|usd_goal_real|                name|      category|country|     state|\n",
      "+--------------+-------------+--------------------+--------------+-------+----------+\n",
      "|          43.0|      4926.39|             Borders|         Drama|     GB|    failed|\n",
      "|          21.0|      2240.39|Spiele für iOS un...|  Mobile Games|     DE|    failed|\n",
      "|          30.0|        700.0|Odyssey Skateboar...|Graphic Design|     US|    failed|\n",
      "|          30.0|       5500.0|Debut EP Album Pr...|           R&B|     US|    failed|\n",
      "|          16.0|       1200.0|GBS Detroit Prese...|    Indie Rock|     US|successful|\n",
      "+--------------+-------------+--------------------+--------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checks dataset structure\n",
    "dataset_check(processed_campaigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     state| count|\n",
      "+----------+------+\n",
      "|    failed|237451|\n",
      "|successful|134609|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checks state column's content\n",
    "processed_campaigns.select(\"state\").groupBy(\"state\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total_duration', 'float'),\n",
       " ('usd_goal_real', 'float'),\n",
       " ('name', 'string'),\n",
       " ('category', 'string'),\n",
       " ('country', 'string'),\n",
       " ('state', 'string')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_campaigns.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----+--------+-------+-----+\n",
      "|total_duration|usd_goal_real|name|category|country|state|\n",
      "+--------------+-------------+----+--------+-------+-----+\n",
      "|             0|            0|   0|       0|      0|    0|\n",
      "+--------------+-------------+----+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checks for N/A\n",
    "processed_campaigns.select([count(when(isnan(c), c)).alias(c) for c in processed_campaigns.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Creating the dataset for Logistic Regression, Decision Tree, and Random Forest\n",
    "\n",
    "Our first three models will be:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "To create our data pipeline, we will rely on indexing and assembling our data using the following stages:\n",
    "- **StringIndexer** for all categorical columns\n",
    "- **OneHotEncoder** for all categorical index columns\n",
    "- **Tokenizer** and **Word2Vec** for the \\<name\\> column\n",
    "- **VectorAssembler** for all feature columns to be assembled into one vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String-indexes the categorical feature columns\n",
    "categorical_feature_columns = processed_campaigns.columns[3:5]\n",
    "string_indexing_feature_columns = [\n",
    "    StringIndexer(inputCol=column, outputCol=\"strindexed_\" + column, handleInvalid=\"skip\")\n",
    "    for column in categorical_feature_columns\n",
    "]\n",
    "\n",
    "# String-indexes the label column\n",
    "string_indexing_label_column = [\n",
    "    StringIndexer(inputCol=\"state\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Note on pyspark 2.3 used on Google Cloud**:  OneHotEncoder and VectorAssembler do not have the \\<handleInvalid\\> attribute. The resulting effect is that pyspark can raise a null error during .fit() procedures despite no na exists in the dataset (see cell in previous part). A solution will be to pass dataset column as dataset.na.drop() later on.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates pipeline stages to one-hot encode each categorical feature column\n",
    "if context == \"local\":\n",
    "    onehot_encoding_feature_columns = [\n",
    "        OneHotEncoder(inputCol = \"strindexed_\" + column, \n",
    "                      outputCol = \"onehot_\" + column,\n",
    "                      handleInvalid = \"keep\")\n",
    "        for column in categorical_feature_columns\n",
    "    ]\n",
    "else:\n",
    "    onehot_encoding_feature_columns = [\n",
    "        OneHotEncoder(inputCol = \"strindexed_\" + column, \n",
    "                      outputCol = \"onehot_\" + column) \n",
    "        for column in categorical_feature_columns\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates pipeline stages to vector assemble each categorical feature column\n",
    "processed_feature_columns = list(map(lambda col_name: \"onehot_\" + col_name, categorical_feature_columns))\n",
    "processed_feature_columns += [\"total_duration\", \"usd_goal_real\"]\n",
    "\n",
    "if context == \"local\":\n",
    "    vectorassembler_stage = VectorAssembler(inputCols=processed_feature_columns, \n",
    "                                            outputCol=\"features_1\",\n",
    "                                            handleInvalid=\"skip\")\n",
    "else:\n",
    "    vectorassembler_stage = VectorAssembler(inputCols=processed_feature_columns, \n",
    "                                            outputCol=\"features_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates pipeline stages to vectorize the <name> column\n",
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"words\")\n",
    "Word2Vec = Word2Vec(vectorSize=20, inputCol=tokenizer.getOutputCol(), outputCol=\"features_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merges the vectors resulting from the categorical feature pipeline and word2vec pipeline\n",
    "merge_features = VectorAssembler(inputCols=[\"features_1\", \"features_2\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembles the data processing pipeline\n",
    "data_processing_pipeline = Pipeline(\n",
    "    stages = string_indexing_feature_columns +\n",
    "    string_indexing_label_column + \n",
    "    onehot_encoding_feature_columns + \n",
    "    [vectorassembler_stage] + \n",
    "    [tokenizer] + \n",
    "    [Word2Vec] +\n",
    "    [merge_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the data processing pipeline\n",
    "first_pipeline = data_processing_pipeline.fit(processed_campaigns.na.drop())\n",
    "first_processed_dataset = first_pipeline.transform(processed_campaigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caches 20% of the dataset for the session for better time performance\n",
    "first_processed_dataset = first_processed_dataset.select(final_columns).sample(0.2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 73890 rows.\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(193,[18,159,181,...|  0.0|\n",
      "|(193,[4,162,181,1...|  1.0|\n",
      "|(193,[28,159,181,...|  0.0|\n",
      "|(193,[42,160,181,...|  0.0|\n",
      "|(193,[28,159,181,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_check(first_processed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Finalizing our dataset for Naive Bayes\n",
    "\n",
    "Our second batch of models will be:\n",
    "- Naive Bayes\n",
    "\n",
    "To create our data pipeline, we will rely on indexing and assembling our data using the following stages:\n",
    "- **StringIndexer** for all categorical columns\n",
    "- **OneHotEncoder** for all categorical index columns\n",
    "- **Tokenizer** and **HashingTF** for the \\<name\\> column\n",
    "- **VectorAssembler** for all feature columns to be assembled into one vector column\n",
    "\n",
    "We use HashingTF for our pipeline because Naive Bayes can only accept positive float values when Word2Vec can output vectors with negative elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates pipeline stages to vectorize the <name> column\n",
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"words\")\n",
    "HashingTF = HashingTF(numFeatures=20, inputCol=tokenizer.getOutputCol(), outputCol=\"features_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembles the data processing pipeline\n",
    "data_processing_pipeline = Pipeline(\n",
    "    stages = string_indexing_feature_columns +\n",
    "    string_indexing_label_column + \n",
    "    onehot_encoding_feature_columns + \n",
    "    [vectorassembler_stage] + \n",
    "    [tokenizer] + \n",
    "    [HashingTF] +\n",
    "    [merge_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the data processing pipeline\n",
    "pipeline_naive_bayes = data_processing_pipeline.fit(processed_campaigns.na.drop())\n",
    "second_processed_dataset = pipeline_naive_bayes.transform(processed_campaigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caches 20% of the dataset for the session for better time performance\n",
    "second_processed_dataset = second_processed_dataset.select(final_columns).sample(0.2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 74522 rows.\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(203,[49,160,181,...|  0.0|\n",
      "|(203,[8,159,181,1...|  0.0|\n",
      "|(203,[23,159,181,...|  0.0|\n",
      "|(203,[42,160,181,...|  0.0|\n",
      "|(203,[6,159,181,1...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_check(second_processed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Running a Logistic Regression Pipeline\n",
    "\n",
    "### 7.1. Declaring model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares hyperparameters\n",
    "training_size = 0.7\n",
    "test_size = 0.3\n",
    "reg_parameters = [0, 0.5, 1., 2.] # must be float values\n",
    "elastic_net_parameters = [0., 0.5, 1.] # must be float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares useful functions\n",
    "def process_confusion_matrix(matrix):\\\n",
    "    \"\"\"\n",
    "    Produces the confusion matrix of a model based on its\n",
    "    binary classification output.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for item in matrix: \n",
    "        items.append(item)\n",
    "        print(item, matrix[item])\n",
    "    if Row(label=0.0, prediction=0.0) in items: \n",
    "        true_negatives = float(matrix[Row(label=0.0, prediction=0.0)])\n",
    "    else: \n",
    "        true_negatives = 0.\n",
    "    if Row(label=1.0, prediction=0.0) in items: \n",
    "        false_negatives = float(matrix[Row(label=1.0, prediction=0.0)])\n",
    "    else: \n",
    "        false_negatives = 0.\n",
    "    if Row(label=0.0, prediction=1.0) in items: \n",
    "        false_positives = float(matrix[Row(label=0.0, prediction=1.0)])\n",
    "    else: \n",
    "        false_positives = 0.\n",
    "    if Row(label=1.0, prediction=1.0) in items: \n",
    "        true_positives = float(matrix[Row(label=1.0, prediction=1.0)])\n",
    "    else: \n",
    "        true_positives = 0.\n",
    "    precision = true_positives/(true_positives+false_positives)\n",
    "    recall = true_positives/(true_positives+false_negatives)\n",
    "    print(\"\\nPrecision score:\", precision)\n",
    "    print(\"Recall score:\", recall)\n",
    "    if precision+recall != 0.: \n",
    "        print(\"F1 score:\", (precision*recall)/(precision+recall))\n",
    "        return precision, recall, (precision*recall)/(precision+recall))\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Creating a model pipeline using Cross-Validation\n",
    "\n",
    "#### 7.2.1. Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a parameter grid\n",
    "lr_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(lr.regParam, reg_parameters).\\\n",
    "    addGrid(lr.elasticNetParam, elastic_net_parameters).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the evaluator\n",
    "lr_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the cross-validation model\n",
    "lr_cv = CrossValidator(estimator=lr, \n",
    "                       estimatorParamMaps=lr_param_grid, \n",
    "                       evaluator=lr_evaluator, \n",
    "                       numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the cross-validation model\n",
    "lr_cv_model = lr_cv.fit(first_processed_dataset.na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was fit using parameters: \n",
      "{Param(parent='CrossValidatorModel_ffc5cd3d18df', name='seed', doc='random seed.'): 5370764324114565524, Param(parent='CrossValidatorModel_ffc5cd3d18df', name='numFolds', doc='number of folds for cross validation'): 5, Param(parent='CrossValidatorModel_ffc5cd3d18df', name='estimator', doc='estimator to be cross-validated'): LogisticRegression_3f2500add73e, Param(parent='CrossValidatorModel_ffc5cd3d18df', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5}, {Param(parent='LogisticRegression_3f2500add73e', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_3f2500add73e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}], Param(parent='CrossValidatorModel_ffc5cd3d18df', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): BinaryClassificationEvaluator_2bb386b8ac20}\n"
     ]
    }
   ],
   "source": [
    "print(\"The model was fit using parameters: \\n\")\n",
    "print(lr_cv_model.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=1.0, prediction=1.0) 5327\n",
      "Row(label=0.0, prediction=0.0) 20628\n",
      "Row(label=1.0, prediction=0.0) 7995\n",
      "Row(label=0.0, prediction=1.0) 3235\n",
      "\n",
      "Precision score: 0.6221677178229386\n",
      "Recall score: 0.3998648851523795\n",
      "F1 score: 0.24341985011880826\n"
     ]
    }
   ],
   "source": [
    "# Provides a confusion matrix\n",
    "lr_label_and_pred = lr_cv_model.transform(first_processed_dataset).select(\"label\", \"prediction\")\n",
    "lr_confusion_matrix = lr_label_and_pred.rdd.zipWithIndex().countByKey()\n",
    "lr_results = process_confusion_matrix(lr_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.4819529278019527\n",
      "coefficients: [0.26758795267590774,0.30009144189370945,1.0121060891880869,0.4060548693466408,0.6444665740258785,-0.30477547008262085,-0.14847142463087093,0.026472049456678765,-0.5186856274399023,-0.4007342827118165,-0.1987309359978946,0.38999189488689034,-0.6246978446955926,1.143156112750401,-0.2885451749640301,0.5821233670881333,0.1644139055976517,-1.5141054469178223,-0.1294286631095084,-0.2340278517642612,1.1653789703418131,-0.0018203295877317746,0.31513882922983005,-1.3210137810236107,0.6207974062004611,-0.27529024081583603,1.0686700990323432,0.15550453494200608,-1.199044592513611,0.3993995032425031,0.3241803063560533,0.20269835383190596,-0.1529378693771232,0.8767678319505534,-0.052461231799360616,0.8303418608092669,-0.7370582536777287,0.09200919649376844,-0.3248781917889076,-0.043543017169981595,0.9789183440991038,0.7882246104833379,1.1544693325442312,-0.19631198661363683,0.21423241330250548,-0.3828016823699003,1.2189437365994513,0.11444284502203682,-0.457094014598452,0.42388279291616426,0.37859645924087487,0.22275921269047494,0.09561850512675897,1.0452805569894545,0.7900769330381922,0.46360810231707233,-0.0064102047656549935,-1.6437160117423353,0.2090062021882015,-0.8979642741783963,0.420034425154794,0.6960026142382482,-0.24675252075875106,-0.1969244016226482,-0.5070503372890998,0.5384045369784366,-0.511694369896808,0.5336751371427157,-0.5661373528088647,-1.222141003585847,-0.18354541818883077,-0.3602106032021402,0.03012229970141287,-0.673893476915037,-0.32875527034730073,-0.647788668498867,1.0745082180983634,0.20843773124610143,0.44381807226478,0.3587898019654281,-0.26561244482897817,0.6652704260377466,0.6166979594938538,-0.8342847937991863,1.0104088304869334,0.607261159137511,-0.3652142908348359,-0.3585113882748937,1.4396087704434535,0.4844280670491087,0.5038856978648766,0.5056707735347742,-1.4249810455750669,-0.15871183111499437,-0.6192784280731236,0.028331923127973935,-0.457807414819817,0.14183730600742184,0.5528504146246702,0.8551307911730587,0.8825870704535466,0.30241646139893436,-0.5888295004413656,0.5220708484743137,-0.10846378947040249,-0.36548185008854284,0.7241627413564824,-1.5310273863535504,-1.0201891917469008,0.5403291375589224,-1.8045894099886253,-0.3155813074046613,-0.4884885196246472,0.6293143823026037,-0.0805354989770407,-0.6942026999907136,0.6374603639037992,-0.1413781863261121,-0.4919954536925765,0.7117847996704371,-0.5526932407587399,0.15964167535811052,0.7378324016603967,-0.2891726721051036,-0.5812463714831821,0.07346591492341888,0.47637990135602964,0.6127928670660638,0.28675830306973094,-0.45175192644901857,0.18102961500788636,-0.004223237227636585,-1.123121267350806,0.79462790697837,-0.9087127165187722,1.1502089328067446,0.6575816027563237,-0.8082635661918253,0.2576237435474826,-1.5446840807857243,-0.6634660407410949,-0.03520035031263797,1.9633898581085725,-0.07240375020402263,0.5837491266653888,0.6328952793339266,0.5434973573701259,-1.0696604095136555,-0.2779065302434452,-0.19708061542641583,1.1095096602428451,0.9499510576981138,-0.2451660581435194,0.206923422157737,2.648868134263445,2.7870791683545706,-46.11624569654934,0.0,-50.44173627565289,0.4441029225835554,0.3439705268116739,0.1344393548010862,0.0427274808983772,0.09515211621343089,0.4957884397864754,0.16388095755969984,-0.4982646283602219,-0.2120936765723446,0.1491947617432134,-0.14022337024782072,0.41191812564909386,0.22722562014732528,-0.5937161687278976,0.26083841739007163,0.17876202291011545,0.6027216603359691,0.25960603097879786,-0.44436012702274935,0.1867899143547953,-57.31930617211474,-50.317589643090095,-0.01803445934672774,-1.465529793164458e-05,-0.6896132395382488,0.3064826460322341,0.07022672298597069,0.7376380066615672,1.0156879412926976,0.5611217611071173,0.16946980420417904,0.37490640913331663,0.389648050435911,0.6128324210314862]\n"
     ]
    }
   ],
   "source": [
    "# Intercept and Coefficients of the regresison model\n",
    "print(\"Intercept: \" + str(lr_cv_model.bestModel.intercept) + \"\\n\"\n",
    "      \"coefficients: \" + str(lr_cv_model.bestModel.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best RegParam is:  0.0 \n",
      " The best ElasticNetParam is: cv_model.bestModel._java_obj.getElasticNetParam()\n"
     ]
    }
   ],
   "source": [
    "# Parameters of the best model\n",
    "print(\"The best RegParam is: \", cv_model.bestModel._java_obj.getRegParam(), \"\\n\",\n",
    "     \"The best ElasticNetParam is:\", cv_model.bestModel._java_obj.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Running a DecisionTreeClassifier Pipeline\n",
    "\n",
    "### 8.1. Declaring model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares hyperparameters\n",
    "max_depth_grid = list(range(2,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Creating a model pipeline using Cross-Validation\n",
    "\n",
    "#### 8.2.1. Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the estimator\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a parameter grid\n",
    "dt_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(dt.maxDepth, max_depth_grid).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the evaluator\n",
    "dt_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", \n",
    "                                             metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the cross-validation model\n",
    "dt_cv = CrossValidator(estimator=dt, \n",
    "                       estimatorParamMaps=dt_param_grid, \n",
    "                       evaluator=dt_evaluator, \n",
    "                       numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fits the cross-validation model\n",
    "dt_cv_model = dt_cv.fit(first_processed_dataset.na.drop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=1.0, prediction=1.0) 4964\n",
      "Row(label=0.0, prediction=0.0) 19102\n",
      "Row(label=1.0, prediction=0.0) 8358\n",
      "Row(label=0.0, prediction=1.0) 4761\n",
      "\n",
      "Precision score: 0.5104370179948586\n",
      "Recall score: 0.37261672421558323\n",
      "F1 score: 0.21538595044908232\n"
     ]
    }
   ],
   "source": [
    "# Provides a confusion matrix\n",
    "dt_cv_label_and_pred = cv_model.transform(first_processed_dataset).select(\"label\", \"prediction\")\n",
    "dt_cv_confusion_matrix = dt_cv_label_and_pred.rdd.zipWithIndex().countByKey()\n",
    "dt_cv_results = process_confusion_matrix(dt_cv_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best MaxDepth is: 3\n"
     ]
    }
   ],
   "source": [
    "print('The best MaxDepth is:', cv_model.bestModel._java_obj.getMaxDepth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_e12c75433b1a, depth=3, numNodes=7, numClasses=2, numFeatures=193\n"
     ]
    }
   ],
   "source": [
    "print(cv_model.bestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Creating a model pipeline using Train-Test split\n",
    "\n",
    "#### 8.3.1. Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the dataset between training and validation sets\n",
    "training, test = first_processed_dataset.randomSplit([training_size, test_size], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the estimator\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the evaluator\n",
    "dt_tt_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fits the cross-validation model\n",
    "dt_tt_model = dt.fit(training.na.drop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+---------------+--------------------+\n",
      "|            features|label|prediction|  rawPrediction|         probability|\n",
      "+--------------------+-----+----------+---------------+--------------------+\n",
      "|(193,[0,159,181,1...|  1.0|       0.0| [1138.0,149.0]|[0.88422688422688...|\n",
      "|(193,[0,159,181,1...|  0.0|       0.0|[2358.0,1823.0]|[0.56397990911265...|\n",
      "|(193,[0,159,181,1...|  0.0|       0.0|  [999.0,440.0]|[0.69423210562890...|\n",
      "|(193,[1,160,181,1...|  0.0|       0.0|    [408.0,9.0]|[0.97841726618705...|\n",
      "|(193,[2,159,181,1...|  1.0|       0.0|  [999.0,440.0]|[0.69423210562890...|\n",
      "+--------------------+-----+----------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicts on training data\n",
    "pred_test = traintest_model.transform(test)\n",
    "\n",
    "# Provides a confusion matrix\n",
    "dt_tt_label_and_pred = pred_test.select(\"label\", \"prediction\")\n",
    "dt_tt_confusion_matrix = dt_tt_label_and_pred.rdd.zipWithIndex().countByKey()\n",
    "dt_tt_results = process_confusion_matrix(dt_tt_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.4397729058969222\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(pred_test)\n",
    "print(\"The test error is\", 1.0 - accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_e4af082e9aec, depth=5, numNodes=47, numClasses=2, numFeatures=193\n"
     ]
    }
   ],
   "source": [
    "print(traintest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Running a Random Forest Pipeline\n",
    "\n",
    "### 9.1. Declaring model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares hyperparameters\n",
    "max_depth_grid = map(float,list(range(2,10))) # must be float values\n",
    "minimum_info_grain = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5] # must be float values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Creating a model pipeline using cross-validation\n",
    "\n",
    "#### 9.2.1. Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the estimator\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a parameter grid\n",
    "rf_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(random_forest_with_crossvalidation.maxDepth, max_depth_grid).\\\n",
    "    addGrid(random_forest_with_crossvalidation.minInfoGain, minimum_info_grain).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the evaluator\n",
    "rf_evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the cross-validation model\n",
    "rf_cv = CrossValidator(estimator=rf, \n",
    "                       estimatorParamMaps=rf_param_grid, \n",
    "                       evaluator=rf_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fits the cross-validation model\n",
    "rf_cv_model = rf_cv.fit(first_processed_dataset.na.drop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=1.0, prediction=1.0) 1899\n",
      "Row(label=0.0, prediction=0.0) 23158\n",
      "Row(label=1.0, prediction=0.0) 11423\n",
      "Row(label=0.0, prediction=1.0) 705\n",
      "\n",
      "Precision score: 0.7292626728110599\n",
      "Recall score: 0.14254616423960367\n",
      "F1 score: 0.11923898028381265\n"
     ]
    }
   ],
   "source": [
    "# Provides a confusion matrix\n",
    "rf_label_and_pred = rf_cv_model.transform(first_processed_dataset).select('label', 'prediction')\n",
    "rf_confusion_matrix = rf_label_and_pred.rdd.zipWithIndex().countByKey()\n",
    "rf_results = process_confusion_matrix(rf_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel: uid=RandomForestClassifier_5aa6fa19503c, numTrees=20, numClasses=2, numFeatures=193\n"
     ]
    }
   ],
   "source": [
    "print(rf_cv_model.bestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Running a Naive Bayes Pipeline\n",
    "\n",
    "### 10.1. Finalizing the data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares hyperparameters\n",
    "smoothing = map(float, list(range(0,10))) # must be float values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Creating a model pipeline using cross-validation\n",
    "\n",
    "#### 10.2.1. Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the estimator\n",
    "nb = NaiveBayes(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a parameter grid\n",
    "nb_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(nb.smoothing, smoothing).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the evaluator\n",
    "nb_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the cross-validation model\n",
    "nb_cv = CrossValidator(estimator = nb, \n",
    "                       estimatorParamMaps = nb_param_grid, \n",
    "                       evaluator = nb_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fits the cross-validation model\n",
    "nb_cv_model = nb_cv.fit(second_processed_dataset.na.drop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.2. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, prediction=1.0) 17457\n",
      "Row(label=1.0, prediction=1.0) 11919\n",
      "Row(label=0.0, prediction=0.0) 6285\n",
      "Row(label=1.0, prediction=0.0) 1350\n",
      "\n",
      "Precision score: 0.4057393790849673\n",
      "Recall score: 0.8982591001582636\n",
      "F1 score: 0.2794934927893071\n"
     ]
    }
   ],
   "source": [
    "# Provides a confusion matrix\n",
    "nb_label_and_pred = cv_model.transform(second_processed_dataset).select('label', 'prediction')\n",
    "nb_confusion_matrix = nb_label_and_pred.rdd.zipWithIndex().countByKey()\n",
    "nb_results = process_confusion_matrix(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameter smoothing has best value: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The parameter smoothing has best value:\", nb_cv_model.bestModel._java_obj.getSmoothing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesModel: uid=NaiveBayes_cb21321f226a, modelType=multinomial, numClasses=2, numFeatures=203\n"
     ]
    }
   ],
   "source": [
    "print(nb_cv_model.bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
